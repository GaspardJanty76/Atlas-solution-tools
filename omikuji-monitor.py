import discord
from discord.ext import tasks
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import os
import sys

# Correction de l'encodage pour √©viter les erreurs d'affichage
sys.stdout.reconfigure(encoding="utf-8")
load_dotenv()

TOKEN = os.getenv("DISCORD_TOKEN")
CHANNEL_ID = 1215697019574812752  
URL = "https://omikujistore.com/collections/francais?limit=48"

# Initialisation du bot
intents = discord.Intents.default()
bot = discord.Client(intents=intents)

last_scraped_data = None  # Stocke les derni√®res donn√©es pour comparer les changements

def scrape_website():
    """ Fonction de scraping qui retourne les donn√©es d'un article. """
    global last_scraped_data
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(URL, headers=headers)

    if response.status_code != 200:
        print(f"[ERREUR] Impossible de r√©cup√©rer la page. Code HTTP: {response.status_code}")
        return None

    soup = BeautifulSoup(response.text, "html.parser")

    # üîç S√©lection des √©l√©ments avec v√©rification
    title_element = soup.select_one(".spf-product-card__title a")
    price_element = soup.select_one(".spf-product-card__price-wrapper .money")
    link_element = soup.select_one(".spf-product-card__title a")

    if not title_element or not price_element or not link_element:
        print("[ERREUR] Impossible de r√©cup√©rer certains √©l√©ments du site.")
        return None

    # Extraction des donn√©es
    title = title_element.text.strip()
    price = price_element.text.strip()
    link = "https://omikujistore.com" + link_element["href"]  # Ajoute le domaine

    data = {"title": title, "price": price, "link": link}

    # V√©rifie si les donn√©es ont chang√©
    if last_scraped_data is None or data != last_scraped_data:
        last_scraped_data = data
        return data
    return None

@tasks.loop(minutes=5)  # V√©rifie toutes les 5 minutes
async def check_website():
    channel = bot.get_channel(CHANNEL_ID)

    if channel is None:
        print("[ERREUR] Canal introuvable. V√©rifiez l'ID du canal.")
        return

    new_data = scrape_website()
    if new_data:
        embed = discord.Embed(
            title=new_data["title"],
            description=f"**Prix:** {new_data['price']}",
            url=new_data["link"],
            color=discord.Color.green(),
        )
        embed.set_footer(text="Nouveau produit d√©tect√© ! üöÄ")
        await channel.send(embed=embed)
        print("[INFO] Nouveau produit envoy√© sur Discord.")

@bot.event
async def on_ready():
    print(f"{bot.user} est connect√© ! ‚úÖ")
    check_website.start()

bot.run(TOKEN)
